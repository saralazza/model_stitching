{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:18:50.404545Z",
     "iopub.status.busy": "2025-11-12T17:18:50.404209Z",
     "iopub.status.idle": "2025-11-12T17:18:50.409788Z",
     "shell.execute_reply": "2025-11-12T17:18:50.408816Z",
     "shell.execute_reply.started": "2025-11-12T17:18:50.404507Z"
    },
    "papermill": {
     "duration": 4.849221,
     "end_time": "2025-11-11T16:09:01.116245",
     "exception": false,
     "start_time": "2025-11-11T16:08:56.267024",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed and reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:18:50.411645Z",
     "iopub.status.busy": "2025-11-12T17:18:50.411434Z",
     "iopub.status.idle": "2025-11-12T17:18:50.435736Z",
     "shell.execute_reply": "2025-11-12T17:18:50.435127Z",
     "shell.execute_reply.started": "2025-11-12T17:18:50.411629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU\n",
    "    \n",
    "    # --- 2. Set CUDNN backend to be deterministic ---\n",
    "    # This can slow down training, but is necessary for reproducibility\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    Seeder function for DataLoader workers.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# --- 3. Run the seeder ---\n",
    "seed_everything(SEED)\n",
    "\n",
    "# --- 4. Create a generator for DataLoaders ---\n",
    "# We will pass this to all DataLoaders\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "print(f\"All seeds set to {SEED} and CUDNN is in deterministic mode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028907,
     "end_time": "2025-11-11T16:09:01.176201",
     "exception": false,
     "start_time": "2025-11-11T16:09:01.147294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config and Parameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:18:50.445512Z",
     "iopub.status.busy": "2025-11-12T17:18:50.445251Z",
     "iopub.status.idle": "2025-11-12T17:18:50.460759Z",
     "shell.execute_reply": "2025-11-12T17:18:50.460049Z",
     "shell.execute_reply.started": "2025-11-12T17:18:50.445489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CONFIG = {\n",
    "    #  novedad -> We now have two models to save\n",
    "    # --- MODIFIED: Changed to path templates ---\n",
    "    \"TEXT_VE_PATH_TPL\": \"best_text_ve_fold_{}.pth\",\n",
    "    \"TRANSLATOR_PATH_TPL\": \"best_translator_mlp_fold_{}.pth\",\n",
    "    \"DEVICE\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \n",
    "    # --- Single-Stage Training ---\n",
    "    \"EPOCHS\": 150,\n",
    "    \"PATIENCE\": 30,\n",
    "    \n",
    "    # --- NEW: K-Fold Configuration ---\n",
    "    \"N_FOLDS\": 10,\n",
    "    \"RANDOM_STATE\": 42,\n",
    "    \n",
    "    # --- Architecture/Loss Params ---\n",
    "    \"HIDDEN_FEATURES\": 3072, \n",
    "    \"NUM_BLOCKS\": 2,\n",
    "    \"DROPOUT_RATE\": 0.3832296399028748,     \n",
    "    \"LR\": 1.7749224152998916e-05,             \n",
    "    \"WEIGHT_DECAY\": 0.0008723639231133962,\n",
    "    \n",
    "    # --- Hybrid Loss Params ---\n",
    "    \"MARGIN\": 0.3898481154806984,\n",
    "    \"TEMPERATURE\": 0.010879304099273002,\n",
    "    \"HYBRID_ALPHA\": 0,\n",
    "    \"MIXUP_ALPHA\": 0.23197266859653176,\n",
    "    \n",
    "    #  novedad -> New VAE Params\n",
    "    \"LATENT_DIM\": 2048,       # The \"noisy\" space between the two models\n",
    "    \"KLD_WEIGHT\": 1.9543552300752537e-06,     # \n",
    "    \n",
    "    # --- General Settings ---\n",
    "    \"BATCH_SIZE\": 256,\n",
    "    \"ACCUMULATION_STEPS\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034925,
     "end_time": "2025-11-11T16:09:01.674431",
     "exception": false,
     "start_time": "2025-11-11T16:09:01.639506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:18:50.461729Z",
     "iopub.status.busy": "2025-11-12T17:18:50.461496Z",
     "iopub.status.idle": "2025-11-12T17:18:54.509317Z",
     "shell.execute_reply": "2025-11-12T17:18:54.508628Z",
     "shell.execute_reply.started": "2025-11-12T17:18:50.461706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # <-- NEW: Import KFold\n",
    "\n",
    "# --- 2. Data Loading ---\n",
    "# We now load the *full* dataset here. \n",
    "# The splitting into train/val will be handled by KFold in the training loop.\n",
    "try:\n",
    "    full_train_data = np.load(\"/kaggle/input/train.npz\", allow_pickle=True)\n",
    "    all_text_embeddings = torch.from_numpy(full_train_data['captions/embeddings']).float()\n",
    "    all_image_embeddings = torch.from_numpy(full_train_data['images/embeddings']).float()\n",
    "\n",
    "    num_images = all_image_embeddings.shape[0]\n",
    "    num_captions_per_image = all_text_embeddings.shape[0] // num_images\n",
    "\n",
    "    # --- NEW: Define the KFold splitter ---\n",
    "    # We split on image_indices to keep all captions for one image together\n",
    "    image_indices = np.arange(num_images)\n",
    "    kfold = KFold(n_splits=CONFIG['N_FOLDS'], shuffle=True, random_state=CONFIG['RANDOM_STATE'])\n",
    "\n",
    "    print(f\"Data loaded: {all_text_embeddings.shape[0]} text embeddings, {all_image_embeddings.shape[0]} image embeddings.\")\n",
    "    print(f\"KFold splitter created with {CONFIG['N_FOLDS']} splits.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Please make sure the 'train.npz' file is in the correct directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027698,
     "end_time": "2025-11-11T16:09:11.069920",
     "exception": false,
     "start_time": "2025-11-11T16:09:11.042222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:18:54.510408Z",
     "iopub.status.busy": "2025-11-12T17:18:54.510104Z",
     "iopub.status.idle": "2025-11-12T17:18:54.521810Z",
     "shell.execute_reply": "2025-11-12T17:18:54.521163Z",
     "shell.execute_reply.started": "2025-11-12T17:18:54.510376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 3. Model Architecture (V5 - VAE -> MLP) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 3A. The GeGLU Activation Module ---\n",
    "class GeGLU(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(in_features, out_features * 2)\n",
    "        self.gelu = nn.GELU()\n",
    "    def forward(self, x):\n",
    "        proj_out = self.proj(x)\n",
    "        a, b = proj_out.chunk(2, dim=-1)\n",
    "        return self.gelu(a) * b\n",
    "\n",
    "# --- 3B. The Residual Block with GeGLU ---\n",
    "class ResidualBlockGeGLU(nn.Module):\n",
    "    def __init__(self, features, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            GeGLU(features, features), \n",
    "            nn.BatchNorm1d(features),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "#  novedad -> 3C. The *new* Text VAE\n",
    "class TextVariationalEncoder(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_features)\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_features, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(hidden_features, latent_dim)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return mu + epsilon * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_log_var(h)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return z, mu, log_var\n",
    "\n",
    "#  novedad -> 3D. The Translator (Your HybridMLP)\n",
    "class TranslatorMLP(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_features, num_blocks, dropout_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        # This model now takes the 'latent_dim' as its input\n",
    "        backbone_layers = [\n",
    "            nn.Linear(in_features, hidden_features, bias=False),\n",
    "            nn.BatchNorm1d(hidden_features),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5)\n",
    "        ]\n",
    "        for _ in range(num_blocks):\n",
    "            backbone_layers.append(\n",
    "                ResidualBlockGeGLU(hidden_features, dropout_rate) # Using GeGLU\n",
    "            )\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "        \n",
    "        self.translator_head = nn.Sequential(\n",
    "            nn.Linear(hidden_features, hidden_features // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_features // 2, out_features) # out_features = 1536\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_representation = self.backbone(x)\n",
    "        output = self.translator_head(shared_representation)\n",
    "        return F.normalize(output, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027222,
     "end_time": "2025-11-11T16:09:11.369959",
     "exception": false,
     "start_time": "2025-11-11T16:09:11.342737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:18:54.544882Z",
     "iopub.status.busy": "2025-11-12T17:18:54.544681Z",
     "iopub.status.idle": "2025-11-12T17:18:54.564773Z",
     "shell.execute_reply": "2025-11-12T17:18:54.563986Z",
     "shell.execute_reply.started": "2025-11-12T17:18:54.544868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class PureContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "    def forward(self, pred_norm, target_norm):\n",
    "        sim_matrix = torch.matmul(pred_norm, target_norm.T) / self.temperature\n",
    "        labels = torch.arange(pred_norm.size(0), device=pred_norm.device)\n",
    "        return F.cross_entropy(sim_matrix, labels)\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    def forward(self, text_embeds, img_embeds_norm):\n",
    "        sim_matrix = text_embeds @ img_embeds_norm.T\n",
    "        positive_scores = torch.diag(sim_matrix)\n",
    "        mask = torch.eye(text_embeds.size(0), dtype=torch.bool, device=text_embeds.device)\n",
    "        sim_matrix_masked = sim_matrix.masked_fill(mask, -float('inf'))\n",
    "        hard_negative_scores = sim_matrix_masked.max(dim=1)[0]\n",
    "        return F.relu(self.margin - positive_scores + hard_negative_scores).mean()\n",
    "\n",
    "# --- 5B. FAST VALIDATION (for early stopping) ---\n",
    "def validation_fn(text_ve, translator_model, val_loader, criterion_triplet, criterion_pure, alpha, kld_weight, device):\n",
    "    text_ve.eval()\n",
    "    translator_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, image_batch in val_loader:\n",
    "            text_batch, image_batch = text_batch.to(device), image_batch.to(device)\n",
    "            \n",
    "            #  novedad -> VAE -> MLP flow\n",
    "            z, mu, log_var = text_ve(text_batch)\n",
    "            pred_embeddings = translator_model(z)\n",
    "            \n",
    "            target_embeddings = F.normalize(image_batch, p=2, dim=1)\n",
    "            \n",
    "            # Calculate Hybrid Loss\n",
    "            loss_triplet = criterion_triplet(pred_embeddings, target_embeddings)\n",
    "            loss_pure = criterion_pure(pred_embeddings, target_embeddings)\n",
    "            hybrid_loss = (alpha * loss_triplet) + ((1 - alpha) * loss_pure)\n",
    "            \n",
    "            # Calculate KLD Loss\n",
    "            kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            kld_loss = kld_loss / text_batch.size(0)\n",
    "            \n",
    "            loss = hybrid_loss + (kld_weight * kld_loss)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "# --- 5C. MRR CALCULATION (stable 1-vs-batch) ---\n",
    "def calculate_mrr(text_ve, translator_model, val_loader, device):\n",
    "    text_ve.eval()\n",
    "    translator_model.eval()\n",
    "    all_reciprocal_ranks = []\n",
    "    with torch.no_grad():\n",
    "        for text_batch, image_batch in val_loader:\n",
    "            text_batch = text_batch.to(device)\n",
    "            image_batch = image_batch.to(device)\n",
    "            \n",
    "            #  novedad -> VAE -> MLP flow\n",
    "            z, _, _ = text_ve(text_batch) # We sample z\n",
    "            pred_embeddings_norm = translator_model(z)\n",
    "            \n",
    "            target_embeddings_norm = F.normalize(image_batch, p=2, dim=1)\n",
    "            sim_matrix = pred_embeddings_norm @ target_embeddings_norm.T\n",
    "            \n",
    "            correct_scores = torch.diag(sim_matrix).unsqueeze(1)\n",
    "            ranks = (sim_matrix >= correct_scores).sum(dim=1).float()\n",
    "            reciprocal_ranks = 1.0 / ranks\n",
    "            all_reciprocal_ranks.append(reciprocal_ranks)\n",
    "            \n",
    "    mrr = torch.cat(all_reciprocal_ranks).mean().item()\n",
    "    return mrr\n",
    "\n",
    "# --- 5D. MIXUP ---\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0: lam = np.random.beta(alpha, alpha)\n",
    "    else: lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    indices = torch.randperm(batch_size, device=x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[indices, :]\n",
    "    mixed_y = lam * y + (1 - lam) * y[indices, :]\n",
    "    return mixed_x, mixed_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027857,
     "end_time": "2025-11-11T16:09:11.757675",
     "exception": false,
     "start_time": "2025-11-11T16:09:11.729818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T17:20:07.152424Z",
     "iopub.status.busy": "2025-11-12T17:20:07.151854Z",
     "iopub.status.idle": "2025-11-12T17:20:15.219620Z",
     "shell.execute_reply": "2025-11-12T17:20:15.218666Z",
     "shell.execute_reply.started": "2025-11-12T17:20:07.152401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_fold_mrr = []\n",
    "\n",
    "# =====================================================================================\n",
    "#  NEW: K-FOLD OUTER LOOP\n",
    "# =====================================================================================\n",
    "for fold, (train_image_indices, val_image_indices) in enumerate(kfold.split(image_indices)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"--- STARTING FOLD {fold+1}/{CONFIG['N_FOLDS']} ---\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # --- 1. Create Datasets & DataLoaders for this fold ---\n",
    "    \n",
    "    # Get image embeddings for this fold\n",
    "    train_image_emb = all_image_embeddings[train_image_indices]\n",
    "    val_image_emb = all_image_embeddings[val_image_indices]\n",
    "\n",
    "    # Create the expanded training image embeddings (one for each caption)\n",
    "    train_image_emb_expanded = train_image_emb.repeat_interleave(num_captions_per_image, dim=0)\n",
    "\n",
    "    # Get corresponding text caption embeddings for this fold\n",
    "    train_caption_indices = [i for idx in train_image_indices for i in range(idx * num_captions_per_image, (idx + 1) * num_captions_per_image)]\n",
    "    val_caption_indices = [i for idx in val_image_indices for i in range(idx * num_captions_per_image, (idx + 1) * num_captions_per_image)]\n",
    "\n",
    "    train_text_emb = all_text_embeddings[train_caption_indices]\n",
    "    val_text_emb = all_text_embeddings[val_caption_indices]\n",
    "    \n",
    "    # For validation, we only need one caption per image\n",
    "    val_text_emb_one_per_image = val_text_emb[::num_captions_per_image]\n",
    "\n",
    "    # Create TensorDatasets and DataLoaders\n",
    "    train_dataset = TensorDataset(train_text_emb, train_image_emb_expanded)\n",
    "    val_dataset = TensorDataset(val_text_emb_one_per_image, val_image_emb)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CONFIG['BATCH_SIZE'], \n",
    "        shuffle=True,\n",
    "        worker_init_fn=seed_worker,  # <-- Add this\n",
    "        generator=g                 # <-- Add this\n",
    "    )    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'])\n",
    "\n",
    "    print(f\"Fold {fold+1}: Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
    "\n",
    "    # --- 2. Re-initialize Models, Losses, and Optimizer for this fold ---\n",
    "    text_ve = TextVariationalEncoder(\n",
    "        in_features=all_text_embeddings.shape[1],\n",
    "        hidden_features=CONFIG['LATENT_DIM'],\n",
    "        latent_dim=CONFIG['LATENT_DIM']\n",
    "    ).to(CONFIG['DEVICE'])\n",
    "\n",
    "    translator_model = TranslatorMLP(\n",
    "        in_features=CONFIG['LATENT_DIM'],\n",
    "        out_features=all_image_embeddings.shape[1],\n",
    "        hidden_features=CONFIG['HIDDEN_FEATURES'],\n",
    "        num_blocks=CONFIG['NUM_BLOCKS'],\n",
    "        dropout_rate=CONFIG['DROPOUT_RATE']\n",
    "    ).to(CONFIG['DEVICE'])\n",
    "\n",
    "    criterion_triplet = TripletLoss(margin=CONFIG['MARGIN'])\n",
    "    criterion_pure = PureContrastiveLoss(temperature=CONFIG['TEMPERATURE'])\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        itertools.chain(text_ve.parameters(), translator_model.parameters()),\n",
    "        lr=CONFIG['LR'],\n",
    "        weight_decay=CONFIG['WEIGHT_DECAY']\n",
    "    )\n",
    "    total_steps = len(train_loader) * CONFIG['EPOCHS']\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "    \n",
    "    # --- 3. Training Loop for this fold ---\n",
    "    best_finetune_mrr = -1.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(CONFIG['EPOCHS']):\n",
    "        text_ve.train()\n",
    "        translator_model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        # --- MODIFIED: Added fold info to tqdm description ---\n",
    "        batch_iterator = tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}/{CONFIG['EPOCHS']}\")\n",
    "        \n",
    "        for i, (text_batch, image_batch) in enumerate(batch_iterator):\n",
    "            text_batch = text_batch.to(CONFIG['DEVICE'])\n",
    "            image_batch = image_batch.to(CONFIG['DEVICE'])\n",
    "            \n",
    "            target_embeddings = F.normalize(image_batch, p=2, dim=1)\n",
    "            mixed_text, mixed_targets = mixup_data(text_batch, target_embeddings, alpha=CONFIG['MIXUP_ALPHA'])\n",
    "\n",
    "            z, mu, log_var = text_ve(mixed_text)\n",
    "            pred_embeddings = translator_model(z)\n",
    "            \n",
    "            loss_triplet = criterion_triplet(pred_embeddings, mixed_targets)\n",
    "            loss_pure = criterion_pure(pred_embeddings, mixed_targets)\n",
    "            hybrid_loss = (CONFIG['HYBRID_ALPHA'] * loss_triplet) + ((1 - CONFIG['HYBRID_ALPHA']) * loss_pure)\n",
    "            \n",
    "            kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "            kld_loss = kld_loss / mixed_text.size(0)\n",
    "            \n",
    "            loss = hybrid_loss + (CONFIG['KLD_WEIGHT'] * kld_loss)\n",
    "            loss = loss / CONFIG['ACCUMULATION_STEPS']\n",
    "            loss.backward()\n",
    "\n",
    "            if (i + 1) % CONFIG['ACCUMULATION_STEPS'] == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_train_loss += loss.item() * CONFIG['ACCUMULATION_STEPS']\n",
    "            batch_iterator.set_postfix({\"Train Loss\": f\"{loss.item() * CONFIG['ACCUMULATION_STEPS']:.4f}\"})\n",
    "            \n",
    "        # --- Validation ---\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        val_mrr = calculate_mrr(text_ve, translator_model, val_loader, CONFIG['DEVICE'])\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        print(f\"Fold {fold+1} Epoch {epoch+1} -> Train Loss: {avg_train_loss:.4f} | Val MRR: {val_mrr:.4f} | LR: {current_lr:e}\")\n",
    "        \n",
    "        # train_loss_history.append(avg_train_loss) # Optional: you might want to average this across folds\n",
    "        # finetune_mrr_history.append(val_mrr)\n",
    "        \n",
    "        if val_mrr > best_finetune_mrr:\n",
    "            best_finetune_mrr = val_mrr\n",
    "            \n",
    "            # --- MODIFIED: Use the fold-specific path templates ---\n",
    "            text_ve_path = CONFIG['TEXT_VE_PATH_TPL'].format(fold)\n",
    "            translator_path = CONFIG['TRANSLATOR_PATH_TPL'].format(fold)\n",
    "            \n",
    "            torch.save(text_ve.state_dict(), text_ve_path)\n",
    "            torch.save(translator_model.state_dict(), translator_path)\n",
    "            print(f\"  ðŸ† New best MRR for Fold {fold+1}! Saving models to {text_ve_path}...\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG['PATIENCE']:\n",
    "                print(f\"Early stopping triggered for Fold {fold+1}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\nâœ… Fold {fold+1} finished. Best validation MRR: {best_finetune_mrr:.4f}\")\n",
    "    all_fold_mrr.append(best_finetune_mrr)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"âœ… All {CONFIG['N_FOLDS']} folds trained! \")\n",
    "print(f\"Mean Validation MRR: {np.mean(all_fold_mrr):.4f} (Std: {np.std(all_fold_mrr):.4f})\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 29.47589,
     "end_time": "2025-11-11T20:00:33.920373",
     "exception": false,
     "start_time": "2025-11-11T20:00:04.444483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-12T17:18:54.588225Z",
     "iopub.status.idle": "2025-11-12T17:18:54.588510Z",
     "shell.execute_reply": "2025-11-12T17:18:54.588407Z",
     "shell.execute_reply.started": "2025-11-12T17:18:54.588393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"--- Generating submission.csv\") \n",
    "\n",
    "# --- 1. Load the test data ---\n",
    "try:\n",
    "    test_data = np.load(\"/kaggle/input/test.clean.npz\", allow_pickle=True)\n",
    "    test_text_emb = torch.from_numpy(test_data['captions/embeddings']).float()\n",
    "    test_caption_ids = test_data['captions/ids']\n",
    "    test_loader = DataLoader(test_text_emb, batch_size=CONFIG['BATCH_SIZE'])\n",
    "    print(f\"Test data and caption IDs loaded: {len(test_caption_ids)} samples.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Please make sure the 'test.clean.npz' file is in the correct directory.\")\n",
    "    # Exit or raise error if you can't load test data\n",
    "    \n",
    "# --- 2. Loop through all folds to get predictions ---\n",
    "all_predictions_list = []\n",
    "\n",
    "for fold in range(CONFIG['N_FOLDS']):\n",
    "    print(f\"--- Generating predictions for Fold {fold+1}/{CONFIG['N_FOLDS']} ---\")\n",
    "    \n",
    "    # --- Define model paths for this fold ---\n",
    "    text_ve_path = CONFIG['TEXT_VE_PATH_TPL'].format(fold)\n",
    "    translator_path = CONFIG['TRANSLATOR_PATH_TPL'].format(fold)\n",
    "\n",
    "    # --- Load the best VAE and Translator models for this fold ---\n",
    "    text_ve = TextVariationalEncoder(\n",
    "        in_features=all_text_embeddings.shape[1],\n",
    "        hidden_features=CONFIG['LATENT_DIM'],\n",
    "        latent_dim=CONFIG['LATENT_DIM']\n",
    "    ).to(CONFIG['DEVICE'])\n",
    "\n",
    "    translator_model = TranslatorMLP(\n",
    "        in_features=CONFIG['LATENT_DIM'],\n",
    "        out_features=all_image_embeddings.shape[1], \n",
    "        hidden_features=CONFIG['HIDDEN_FEATURES'],\n",
    "        num_blocks=CONFIG['NUM_BLOCKS'],\n",
    "        dropout_rate=CONFIG['DROPOUT_RATE']\n",
    "    ).to(CONFIG['DEVICE'])\n",
    "\n",
    "    try:\n",
    "        text_ve.load_state_dict(torch.load(text_ve_path))\n",
    "        translator_model.load_state_dict(torch.load(translator_path))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Could not find model files for fold {fold}: {text_ve_path} or {translator_path}\")\n",
    "        print(\"Please ensure training is complete and files are saved correctly.\")\n",
    "        continue # Skip this fold if models aren't found\n",
    "        \n",
    "    text_ve.eval()\n",
    "    translator_model.eval()\n",
    "\n",
    "    # --- Create predictions in batches for this fold ---\n",
    "    fold_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text_batch in tqdm(test_loader, desc=f\"Predicting Fold {fold+1}\"):\n",
    "            text_batch = text_batch.to(CONFIG['DEVICE'])\n",
    "            \n",
    "            # VAE -> MLP flow\n",
    "            # We sample (z) just like in training/validation\n",
    "            z, _, _ = text_ve(text_batch)\n",
    "            pred_batch = translator_model(z)\n",
    "            \n",
    "            fold_predictions.append(pred_batch.cpu().numpy())\n",
    "    \n",
    "    all_predictions_list.append(np.concatenate(fold_predictions, axis=0))\n",
    "\n",
    "if not all_predictions_list:\n",
    "    print(\"\\nNo predictions were generated. Cannot create submission file.\")\n",
    "else:\n",
    "    # --- 3. Average the predictions from all folds ---\n",
    "    print(f\"\\n--- Averaging predictions from {len(all_predictions_list)} folds ---\")\n",
    "    # Stack all prediction arrays (folds, samples, embedding_dim) and then mean across folds (axis=0)\n",
    "    avg_predictions = np.mean(all_predictions_list, axis=0)\n",
    "    \n",
    "    # --- 4. Format for CSV submission ---\n",
    "    embedding_json_list = [json.dumps(embedding.tolist()) for embedding in avg_predictions]\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_caption_ids,\n",
    "        'embedding': embedding_json_list\n",
    "    })\n",
    "\n",
    "    # --- 5. Save the DataFrame to a CSV file ---\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    print(f\"\\nâœ… Ensembled submission file 'submission.csv' has been generated successfully!\")\n",
    "    print(\"Here's a preview of the first 5 rows:\")\n",
    "    print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8587732,
     "sourceId": 13524858,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14282.321359,
   "end_time": "2025-11-11T20:05:57.625941",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-11T16:07:55.304582",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
